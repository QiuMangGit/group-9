###
### 后端
    cmd # 程序入口，初始化GORM、Gin等
    config #配置参数
    model #存放结构体
    repository #数据库操作
    service -> client #RustPbx
    service -> llm #大模型
### 前端
    front-end 
### 分工
websocket(3) 赵双 郭欣雨 严立仁
webrtc(2)   陈保姜 杜家琦
gin(2)  徐子源 刘枚馨
tts(2)  高一景 李泽昊
asr(2)  马泽 张天烁
llm(3)  王喜悦 乔路皓 丁以淞
###
1. 项目概述

    项目名称：智能语音对话
    项目背景：随着人工智能技术的发展，传统人工客服面临效率和成本挑战。智能对话系统通过自然语言处理和机器学习，能够自动理解和生成语言，提供高效、准确的服务，满足用户实时互动需求，推动行业智能化转型。
    目标与目的：
    实现用户与AI之间的实时语音交互。
    用户可以通过页面点击生成虚拟机器助手，并与其进行语音对话。
    受众/用户：主要面向电商平台（例如：拼多多、淘宝），为其提供智能客服与语音助手服务，提升客服效率。
2. 需求分析
    (1)功能需求
        双向语音通话：
            用户通过页面上的电话图标启动与AI之间的双向语音通话功能。
        新增助手：
            用户点击页面上的“新增助手”按钮，系统生成一个新的虚拟机器人。
    (2)技术要求
        前端：支持响应式设计，能够快速开发与渲染页面。
        后端：支持高并发、高性能，能够实时处理语音数据并支持语音识别与合成功能。
3. 系统设计
### 架构设计
    系统整体架构：前后端分离，后端使用 Go 和 RustPbx 进行核心处理，前端通过 WebRTC 和 WebSocket 实现实时通信。
### 接口设计
  采用 WebSocket 用于实时数据传输，WebRTC 用于音视频通话。
### 技术选型
    前端技术：Vue3 + Vite + TailwindCSS
    选择这些技术是因为它们能够高效开发、支持快速构建且具有较好的可扩展性和维护性。
    后端技术**：

  * **Go 语言**：用于高效处理并发请求，性能良好，适合开发高负载应用。
  * **WebSocket**：适用于实时双向通信，确保语音数据的低延迟传输。
  * **Gin**：Go 语言的轻量级框架，适合构建高效的 HTTP 服务。
  * **RustPbx**：处理 WebRTC 协议，确保语音数据流畅传输。
  * **LLM**：大语言模型，支持自然语言理解和生成。
  * **TTS 和 ASR**：语音合成和语音识别模块，提供语音输入与输出功能。
## 4. 开发流程

### 开发环境

* 使用 Git 进行版本控制。
* 前端和后端分别使用 Vue3 和 Go 开发，结合 WebSocket 和 WebRTC 完成语音通话功能。

### 版本控制

* 使用 Git 进行版本管理，确保团队协作时代码的同步与版本控制。

### 开发流程

1. 需求分析
2. 设计阶段：包括系统设计、架构设计、接口设计。
3. 编码实现：前后端分开开发，模块化构建。
4. 测试阶段：功能测试、性能测试、接口测试等。

---

## 5. 功能模块描述
### 1. 双向语音通话模块
#### 建立连接
步骤：
    前端：
   用户打开页面后，前端通过 WebSocket 与后端建立实时连接。
   WebSocket 用于信令交换，保证 WebRTC P2P 连接的建立、音频流和状态更新。
   前端发送信令信息（例如：SDP offer/answer、ICE候选等）到后端。
   后端（使用 Gin）负责监听 WebSocket 请求，并转发信令信息（offer、answer、ICE候选）到相应的 WebRTC 客户端。
#### 发起通话
 步骤：
    前端：
    用户点击电话图标时，前端通过 WebRTC 接口生成一个新的 RTCPeerConnection。
    前端使用 createOffer() 创建一个 SDP offer。
    生成的 offer 通过 WebSocket 发送到后端。
    后端：
    后端通过接收到的 offer（来自前端）使用 RTCPeerConnection 接口生成 answer 并通过 WebSocket 发送回前端。
#### 收集语音并发送
  步骤：
    前端：
    用户开始讲话后，前端通过 WebRTC 的 getUserMedia() API 获取音频流。
    获取的音频流被传输到 RTCPeerConnection 中进行处理，音频数据通过 WebRTC 发送到后端。
    音频流实时发送给后端的 WebSocket 服务。
***后端**：
  * 后端接收到来自前端的音频数据后，将其转发给 RustPbx 进行处理。
  * RustPbx 负责接收音频流并将其传给 ASR 进行自动语音识别。
#### 处理结果
  步骤：
    RustPbx：
    RustPbx 接收到音频流后，使用 ASR 模块对语音进行识别，并将识别结果传给 LLM。
    LLM 生成响应文本，并将其传递给 TTS。
    TTS：
    TTS 将 LLM 返回的文本转换为语音。
    生成的语音被返回到前端，通过 WebRTC 播放。


####
1.跑通程序
2.定接口
3.分接口
4.接口分人

数据库1-2
前端2
